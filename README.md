># ECE535-635-Project-Repository
>Project on Federated Learning on Multimodal Sensor Data by Byung Woong Ko (Alvin) and Liu Ligeng (Leo)

>**Motivation:**

>  The demand for multimodal FL in research community is increasing due to recent emergence of variety of heterogenous sensor deployments with multiple sensing modalities that serve a single learning application. 

>**Design goals:**

>  Understand and benchmark different multimodal datasets in a federated setting

>**Deliverables:**

>  Understand multiodal fedrated learning

>  Reproduce the results in the given paper (https://drive.google.com/drive/folders/1rWJYkfMavGs1F-H0jykJ5V0fIiwrQdJV)

>  perform per-class accuracy analysis of the results and observe the effect of skewed data distribution onthe per-class accuracy

>  Evaluate the system on a multimodal dataset that is relatively balanced in class distribution

>**System blocks:**

>  To be created and uploaded via link upon completion.

>**HW/SW requirements:**

>  Python, Laptop with CUDA-enabled GPU (Optional, To be decided)

>**Team members responsibilities**

>  Each member will pick a role below and work while still being able to support other members who may be having difficulties with thiers, vise versa.

>**Project timeline**

>  TBD

>**references**

>  Multimodal Federated Learning on IOT Data (https://pure-research.york.ac.uk/ws/portalfiles/portal/
79047763/2109.04833v2.pdf)

>

>

>**-Roles-**          

>Setup:             Byung Woong Ko

>Software:          Byung Woong Ko

>Networking:        Undecided

>Writing:           Undecided

>Research:          Byung Woong Ko

>Algorithm design:  Undecided
